{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je_aAoxOkRG1"
      },
      "source": [
        "# Distances between Observations\n",
        "\n",
        "So far, we have studied relationships between variables (columns) in a data frame. But what about observations (rows)? How do we quantify how \"similar\" two observations are?\n",
        "\n",
        "We will use the Ames housing data set as an example, but to keep things simple, we will work with just three quantitative variables from that data set: the number of bedrooms, the number of bathrooms, and the living area (in square feet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "psk1DQEYMnOU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1lX_v7OWkRG4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bedroom AbvGr</th>\n",
              "      <th>Gr Liv Area</th>\n",
              "      <th>Bathrooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1656</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>896</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1329</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2110</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1629</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2925</th>\n",
              "      <td>3</td>\n",
              "      <td>1003</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2926</th>\n",
              "      <td>2</td>\n",
              "      <td>902</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2927</th>\n",
              "      <td>3</td>\n",
              "      <td>970</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>2</td>\n",
              "      <td>1389</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>3</td>\n",
              "      <td>2000</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2930 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Bedroom AbvGr  Gr Liv Area  Bathrooms\n",
              "0                 3         1656        1.0\n",
              "1                 2          896        1.0\n",
              "2                 3         1329        1.5\n",
              "3                 3         2110        2.5\n",
              "4                 3         1629        2.5\n",
              "...             ...          ...        ...\n",
              "2925              3         1003        1.0\n",
              "2926              2          902        1.0\n",
              "2927              3          970        1.0\n",
              "2928              2         1389        1.0\n",
              "2929              3         2000        2.5\n",
              "\n",
              "[2930 rows x 3 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_housing = pd.read_csv(\"https://raw.githubusercontent.com/kevindavisross/data301/main/data/AmesHousing.txt\", sep=\"\\t\")\n",
        "df_housing[\"Bathrooms\"] = df_housing[\"Full Bath\"] + 0.5 * df_housing[\"Half Bath\"]\n",
        "df_housing_quant = df_housing[[\"Bedroom AbvGr\", \"Gr Liv Area\", \"Bathrooms\"]]\n",
        "df_housing_quant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eWXjPdgkRHE"
      },
      "source": [
        "Shown below is a (three-dimensional) scatterplot of these variables. Consider the two observations connected by a red line. (The label next to each point is its index in the `DataFrame`.) To measure how similar they are, we can calculate the distance between the two points.\n",
        "\n",
        "![](https://github.com/dlsun/pods/blob/master/03-Quantitative-Data/distance.png?raw=1)\n",
        "\n",
        "Calculating the distance between two points is not as straightforward as it might seem because there is more than one way to define distance. The most familiar distance metric is probably _Euclidan distance_, which is the straight-line distance (\"as the crow flies\") between the two points. The formula for calculating this distance is a generalization of the Pythagorean theorem:\n",
        "\n",
        "$$ d({\\bf x}, {\\bf x'}) = \\sqrt{\\sum_{j=1}^D (x_j - x'_j)^2} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FFnFtMjkS7eS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Bedroom AbvGr      3.0\n",
              "Gr Liv Area      970.0\n",
              "Bathrooms          1.0\n",
              "Name: 2927, dtype: float64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = df_housing_quant.loc[2927]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hm8LZOuGS9b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Bedroom AbvGr       2.0\n",
              "Gr Liv Area      1389.0\n",
              "Bathrooms           1.0\n",
              "Name: 2928, dtype: float64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1 = df_housing_quant.loc[2928]\n",
        "x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "brcT2DoikRHF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Bedroom AbvGr      1.0\n",
              "Gr Liv Area     -419.0\n",
              "Bathrooms          0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x - x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H1Cx-BqfkRHK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Bedroom AbvGr         1.0\n",
              "Gr Liv Area      175561.0\n",
              "Bathrooms             0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(x - x1) ** 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w8KRHltGMrI0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "175562.0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "((x - x1) ** 2).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1alhuSntkRHO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "419.0011933157231"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sqrt(((x - x1) ** 2).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbaoZjajkRHT"
      },
      "source": [
        "The beauty of this definition is that it generalizes to more than three dimensions. Even though it is difficult to visualize points in 100-dimensional space, we can calculate distances between them in exactly the same way.\n",
        "\n",
        "However, Euclidean distance is not the only way to measure how far apart two points are. There is also [**Manhattan distance**](https://en.wikipedia.org/wiki/Taxicab_geometry) (also called _taxicab distance_), which measures the distance a taxicab in Manhattan would have to drive to travel from A to B. In Manhattan, taxicabs cannot travel in a straight line (i.e., the green path below) because they have to follow the street grid. But there are multiple paths along the street grid that all have exactly the same length (i.e., the red, yellow, and blue paths below); the Manhattan distance is the length of any one of these shortest paths.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Manhattan_distance.svg/283px-Manhattan_distance.svg.png)\n",
        "\n",
        "The formula for Manhattan distance is actually quite similar to the formula for Euclidean distance. Instead of squaring the differences and taking the square root at the end (as in Euclidean distance), we simply take absolute values:\n",
        "$$ d({\\bf x}, {\\bf x'}) = \\sum_{j=1}^D |x_j - x'_j|. $$\n",
        "\n",
        "The following code calculates Manhattan distance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yGZZUEHskRHU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "420.0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "((x - x1).abs()).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqgSzkAwkRHZ"
      },
      "source": [
        "In general, we can raise the absolute difference to any power $p$ and take the $p$th root.\n",
        "$$ d({\\bf x}, {\\bf x'}) = \\left(\\sum_{j=1}^D |x_j - x'_j|^p\\right)^{1/p}. $$\n",
        "This is called _Minkowski distance_. Manhattan distance and Euclidean distance are special cases of Minkowski distance for $p=1$ and $p=2$, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc25K5ZnkRHb"
      },
      "source": [
        "### Comparison of Euclidean and Manhattan distance\n",
        "\n",
        "The Euclidean distance was essentially just the largest difference. This is because Euclidean distance first _squares_ the differences. The squaring operation has a \"rich get richer\" effect; larger values get magnified by more than smaller values. As a result, the largest differences tend to dominate the Euclidean distance.\n",
        "\n",
        "On the other hand, Manhattan distance treats all differences equally. So Manhattan distance is preferred if we are concerned that an outlier in one variable might dominate the distance metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySlOPzAFkRHc"
      },
      "source": [
        "## The Importance of Scaling\n",
        "\n",
        "Here's something to ponder. There are two pairs of observations in the figure below, one connected by a red line, the other connected by an orange line. Which pair of observations is more similar (assuming we use Euclidean distance)?\n",
        "\n",
        "![](https://github.com/dlsun/pods/blob/master/03-Quantitative-Data/closer.png?raw=1)\n",
        "\n",
        "Let's actually calculate these two distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jP0ls6K1kRHd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "419.0011933157231"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distance between two points connected by red line\n",
        "x = df_housing_quant.loc[2927]\n",
        "x1 = df_housing_quant.loc[2928]\n",
        "\n",
        "np.sqrt(((x - x1) ** 2).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V_KpLBbGkRHh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.0990195135927845"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distance between two points connected by orange line\n",
        "x = df_housing_quant.loc[2498]\n",
        "x1 = df_housing_quant.loc[290]\n",
        "\n",
        "np.sqrt(((x - x1) ** 2).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y5mpdx_kRHl"
      },
      "source": [
        "Surprised by the answer? The scatterplot is deceiving because it automatically scales the variables to make the points fit on the same plot. In reality, the variables are on very different scales. The number of bedrooms and bathrooms range from 0 to 6, while living area is in the thousands. When variables are on such different scales, the variable with the largest variability will dominate the distance metric.\n",
        "\n",
        "The plot below shows the same data, but drawn to scale. We can see that differences in the number of bedrooms and the number of bathrooms hardly matter at all; only the variability in the living area matters.\n",
        "\n",
        "![](https://github.com/dlsun/pods/blob/master/03-Quantitative-Data/closer_rescaled.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbTp75j6kRHm"
      },
      "source": [
        "To obtain distances that agree more with our intuition---and that do not give too much weight to any one variable---we transform the variables to be on the same scale. There are several ways to _scale_ a variable ${\\bf x} = (x_1, \\ldots, x_n)$:\n",
        "\n",
        "- _standardizing_: subtract each value by the mean, then divide by the standard deviation,\n",
        "$$ x_i \\leftarrow \\frac{x_i - \\bar {\\bf x}}{\\text{SD}({\\bf x})} $$\n",
        "- _normalizing_: scale each value so that the variable has length (or \"norm\") 1,\n",
        "$$ x_i \\leftarrow \\frac{x_i}{\\sqrt{\\sum_{i=1}^n x_i^2}} $$\n",
        "- _min/max scaling_: scale each value so that all values are between 0 and 1,\n",
        "$$x_i \\leftarrow \\frac{x_i - \\min({\\bf x})}{\\max({\\bf x}) - \\min({\\bf x})}.$$\n",
        "\n",
        "Warning: the terms \"standardize\" and \"normalize\" are also used to represent other things, so pay careful attention to context.\n",
        "\n",
        "\n",
        "The figure below illustrates what each of these scaling methods do to a synthetic data set with two variables. All three methods scale the variables in similar (but slightly different) ways, resulting in figure-eights with different aspect ratios.  Standardizing also moves the data to be centered around the origin, while min-max scaling moves the data to be in a box whose corners are $(0, 0)$ and $(1, 1)$.\n",
        "\n",
        "![](https://github.com/dlsun/pods/blob/master/03-Quantitative-Data/scaling.png?raw=1)\n",
        "\n",
        "Let's standardize the Ames housing data, and see how it affects the distance metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRl9iuwdM2MX"
      },
      "source": [
        "Let's first just standardize living area to see how the process works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Wo1_ks8CMz6-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0.309212\n",
              "1      -1.194223\n",
              "2      -0.337661\n",
              "3       1.207317\n",
              "4       0.255801\n",
              "          ...   \n",
              "2925   -0.982555\n",
              "2926   -1.182354\n",
              "2927   -1.047836\n",
              "2928   -0.218968\n",
              "2929    0.989715\n",
              "Name: Gr Liv Area, Length: 2930, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df_housing_quant[\"Gr Liv Area\"] - df_housing_quant[\"Gr Liv Area\"].mean()) / df_housing_quant[\"Gr Liv Area\"].std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6lVGs5YM0Ij"
      },
      "source": [
        "Notice that the standardized variable contains negative values, indicating values below the mean.\n",
        "\n",
        "Now we'll standardize all three variables in one step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0ttluusMkRHo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bedroom AbvGr</th>\n",
              "      <th>Gr Liv Area</th>\n",
              "      <th>Bathrooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>0.309212</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.032058</td>\n",
              "      <td>-1.194223</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>-0.337661</td>\n",
              "      <td>-0.398702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>1.207317</td>\n",
              "      <td>1.156819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>0.255801</td>\n",
              "      <td>1.156819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2925</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>-0.982555</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2926</th>\n",
              "      <td>-1.032058</td>\n",
              "      <td>-1.182354</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2927</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>-1.047836</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>-1.032058</td>\n",
              "      <td>-0.218968</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>0.989715</td>\n",
              "      <td>1.156819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2930 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Bedroom AbvGr  Gr Liv Area  Bathrooms\n",
              "0          0.176064     0.309212  -1.176462\n",
              "1         -1.032058    -1.194223  -1.176462\n",
              "2          0.176064    -0.337661  -0.398702\n",
              "3          0.176064     1.207317   1.156819\n",
              "4          0.176064     0.255801   1.156819\n",
              "...             ...          ...        ...\n",
              "2925       0.176064    -0.982555  -1.176462\n",
              "2926      -1.032058    -1.182354  -1.176462\n",
              "2927       0.176064    -1.047836  -1.176462\n",
              "2928      -1.032058    -0.218968  -1.176462\n",
              "2929       0.176064     0.989715   1.156819\n",
              "\n",
              "[2930 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_housing_st = (\n",
        "    (df_housing_quant - df_housing_quant.mean()) /\n",
        "    df_housing_quant.std()\n",
        ")\n",
        "df_housing_st"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osyZTJFCkRH6"
      },
      "source": [
        "The above command is deceptively simple. We actually subtracted a `DataFrame` by a `Series`, then divided the resulting `DataFrame` by another `Series`. We relied on `pandas` to broadcast each `Series` over the right dimension of the `DataFrame`. To be more explicit about the broadcasting, we could have also used the `.sub()` and `.divide()` methods (instead of `-` and `/`) and been explicit about the axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "etj1hXwgkRH7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bedroom AbvGr</th>\n",
              "      <th>Gr Liv Area</th>\n",
              "      <th>Bathrooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>0.309212</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.032058</td>\n",
              "      <td>-1.194223</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>-0.337661</td>\n",
              "      <td>-0.398702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>1.207317</td>\n",
              "      <td>1.156819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>0.255801</td>\n",
              "      <td>1.156819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2925</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>-0.982555</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2926</th>\n",
              "      <td>-1.032058</td>\n",
              "      <td>-1.182354</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2927</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>-1.047836</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>-1.032058</td>\n",
              "      <td>-0.218968</td>\n",
              "      <td>-1.176462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>0.176064</td>\n",
              "      <td>0.989715</td>\n",
              "      <td>1.156819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2930 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Bedroom AbvGr  Gr Liv Area  Bathrooms\n",
              "0          0.176064     0.309212  -1.176462\n",
              "1         -1.032058    -1.194223  -1.176462\n",
              "2          0.176064    -0.337661  -0.398702\n",
              "3          0.176064     1.207317   1.156819\n",
              "4          0.176064     0.255801   1.156819\n",
              "...             ...          ...        ...\n",
              "2925       0.176064    -0.982555  -1.176462\n",
              "2926      -1.032058    -1.182354  -1.176462\n",
              "2927       0.176064    -1.047836  -1.176462\n",
              "2928      -1.032058    -0.218968  -1.176462\n",
              "2929       0.176064     0.989715   1.156819\n",
              "\n",
              "[2930 rows x 3 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_housing_st = (df_housing_quant.\n",
        "                  sub(df_housing_quant.mean(), axis=1).\n",
        "                  divide(df_housing_quant.std(), axis=1))\n",
        "df_housing_st"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m8lvgUJkRIA"
      },
      "source": [
        "Now let's recalculate the distances using this standardized data and see if our conclusions change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iqSyNtiekRIB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.465121112969562"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distance between two points connected by red line\n",
        "x = df_housing_st.loc[2927]\n",
        "x1 = df_housing_st.loc[2928]\n",
        "\n",
        "np.sqrt(((x - x1) ** 2).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LayFUy7ykRIF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.9440754446059385"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distance between two points connected by orange line\n",
        "x = df_housing_st.loc[2498]\n",
        "x1 = df_housing_st.loc[290]\n",
        "\n",
        "np.sqrt(((x - x1) ** 2).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJr63l6JkRII"
      },
      "source": [
        "So, if we first standardize the data, then the pair of observations connected by the red line are more similar than the pair connected by the orange line, which matches our intuition. It is (almost) always a good idea to scale the variables before calculating distances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSIL_3jhkRIJ"
      },
      "source": [
        "## The Scikit-Learn API\n",
        "\n",
        "Scikit-Learn is a machine learning library in Python that we will use extensively later. Since scaling data and calculating distances are essential tasks in machine learning, scikit-learn has built-in functions for carrying out these common tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fveA7pDgkRIL"
      },
      "source": [
        "To scale a variable in scikit-learn, there are three steps:\n",
        "\n",
        "1. First, we declare the scaler that we want to use.\n",
        "2. Next, we \"fit\" the scaler to data. For example, in the case of standardization, this simply calculates and stores the mean and standard deviation to use for standardization.\n",
        "3. Finally, we transform the data. This actually applies the scaling to the data.\n",
        "\n",
        "To standardize data, we use the `StandardScaler`. There is also a `MinMaxScaler` for min-max scaling and a `Normalizer` for normalization (but scikit-learn's `Normalizer` normalizes the rows to be length 1, rather than the columns). See [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) for a complete list of scalers and other preprocessing functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1X2qOj9gkRIN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.17609421,  0.30926506, -1.17666295],\n",
              "       [-1.03223376, -1.19442705, -1.17666295],\n",
              "       [ 0.17609421, -0.33771825, -0.3987698 ],\n",
              "       ...,\n",
              "       [ 0.17609421, -1.04801492, -1.17666295],\n",
              "       [-1.03223376, -0.21900572, -1.17666295],\n",
              "       [ 0.17609421,  0.9898836 ,  1.1570165 ]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df_housing_quant)\n",
        "df_housing_st = scaler.transform(df_housing_quant)\n",
        "\n",
        "df_housing_st"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me6TY7fXkRIW"
      },
      "source": [
        "Notice that scikit-learn returns the standardized data as a plain `numpy` array, rather than a `pandas` `DataFrame`. This is one disadvantage of using scikit-learn; we lose the column names, the row index, and all of the other metadata that `DataFrame`s contain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leeHIXaZkRIX"
      },
      "source": [
        "You might wonder why scikit-learn divides scaling into three separate steps. For example, why is it necessary to separate the fitting step from the transformation step? The reason is that a scaler can be fit to one data set and then used to transform many different data sets, not just the original data set to which it was fit. Since the scaler is fit only once, this guarantees that all subsequent data sets will be scaled in exactly the same way (i.e., with respect to the same mean and standard deviation if using the `StandardScaler`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tkAxf_QkRIZ"
      },
      "source": [
        "Scikit-Learn also has built-in functions for calculating distances. For example, to calculate all pairwise distances between observations (2927, 2498) and (2928, 290), we can use the `euclidean_distances` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SGueiCz5kRIa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.4653712 , 5.81988338],\n",
              "       [3.17266983, 3.94474867]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "x = df_housing_st[[2927, 2498], :]\n",
        "x1 = df_housing_st[[2928, 290], :]\n",
        "\n",
        "euclidean_distances(x, x1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKCYfyeLkRId"
      },
      "source": [
        "The upper left entry of this matrix represents the distance between observations 2927 and 2928, while the lower right entry represents the distance between observations 2498 and 290. Check that they match the distances we calculated earlier using `pandas`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNQkfFgwinvu"
      },
      "source": [
        " There are also other distance metrics available, such as `manhattan_distances`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vlV8zxzgiq5J"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.03733718, 10.06050751],\n",
              "       [ 5.25114189,  5.18868439]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "\n",
        "manhattan_distances(x, x1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
