{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYVDhxtNb74o"
      },
      "source": [
        "# The Vector Space Model\n",
        "\n",
        "We have seen how a single document could be converted into a _bag of words_ (or a bag of $n$-grams) representation. Now we will go one step further, converting an entire corpus of documents into tabular data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0WK4Y2qb74r"
      },
      "source": [
        "## Term Frequencies\n",
        "\n",
        "The bag of words representation gives us a mapping between words and their counts, such as `{..., \"am\": 3, \"i\": 71, \"sam\": 6, ...}`. To turn the bag of words into a vector of numbers, we can simply take the word counts, as follows:\n",
        "\n",
        "| ... | i  | am | sam | ... |\n",
        "|-----|----|----|-----|-----|\n",
        "| ... | 71 |  3 |  6  | ... |\n",
        "\n",
        "If we do this for each document in the corpus, and stack the rows, we obtain a table of numbers called the **term-frequency (TF) matrix**.\n",
        "\n",
        "|        | ... | i  | am | sam | ... |\n",
        "|--------|-----|----|----|-----|-----|\n",
        "|**green_eggs_and_ham**| ... | 71 |  3 |  6  | ... |\n",
        "|**cat_in_the_hat**| ... | 59 | 0 | 0 | ... |\n",
        "|**fox_in_socks**| ... | 13 | 0 | 0 | ... |\n",
        "|...|...|...|...|...|...|\n",
        "|**one_fish_two_fish**| ... | 51 | 3 | 0 | ... |\n",
        "\n",
        "The columns are all words (or _terms_) that appear in the corpus, which collectively make up the _vocabulary_. The idea of representing documents by a vector of numbers is called the _vector space model_.\n",
        "\n",
        "Terminology note: we are use **term frequency (TF)** to refer to the *number* of times the term appears in the document. \"Term frequency\" is also sometimes computed as the *proportion* of words in the document that are equal to the terms (that is, the relative frequency of the term in the document). There are still other ways to define TF (or TF-IDF that we'll see below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgl6jLw3cErP"
      },
      "source": [
        "### Implementation from Scratch\n",
        "\n",
        "Let's obtain the term-frequency matrix for the Dr. Seuss books. First, we read in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q7Vy5COKb74s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "green_eggs_and_ham                I am Sam\\n\\nI am Sam\\nSam I am\\n\\nThat Sam-I-a...\n",
              "cat_in_the_hat                    The sun did not shine.\\nIt was too wet to play...\n",
              "fox_in_socks                      Fox\\nSocks\\nBox\\nKnox\\n\\nKnox in box.\\nFox in ...\n",
              "hop_on_pop                        UP PUP Pup is up.\\nCUP PUP Pup in cup.\\nPUP CU...\n",
              "horton_hears_a_who                On the fifteenth of May, in the jungle of Nool...\n",
              "how_the_grinch_stole_christmas    Every Who\\nDown in Whoville\\nLiked Christmas a...\n",
              "oh_the_places_youll_go            Congratulations!\\nToday is your day.\\nYou're o...\n",
              "one_fish_two_fish                 One fish, two fish, red fish, blue fish,\\nBlac...\n",
              "dtype: object"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "seuss_dir = \"http://dlsun.github.io/pods/data/drseuss/\"\n",
        "seuss_files = [\n",
        "    \"green_eggs_and_ham.txt\", \"cat_in_the_hat.txt\", \"fox_in_socks.txt\",\n",
        "    \"hop_on_pop.txt\", \"horton_hears_a_who.txt\", \"how_the_grinch_stole_christmas.txt\",\n",
        "    \"oh_the_places_youll_go.txt\", \"one_fish_two_fish.txt\"\n",
        "]\n",
        "\n",
        "docs_seuss = pd.Series()\n",
        "for file in seuss_files:\n",
        "    response = requests.get(seuss_dir + file, \"r\")\n",
        "    docs_seuss[file[:-4]] = response.text\n",
        "\n",
        "docs_seuss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UOASR79b74x"
      },
      "source": [
        "Now we apply the bag of words representation to the normalized text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A6VrqvvJb74y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "green_eggs_and_ham                {'i': 71, 'am': 3, 'sam': 3, 'that': 3, 'sam-i...\n",
              "cat_in_the_hat                    {'the': 97, 'sun': 2, 'did': 8, 'not': 37, 'sh...\n",
              "fox_in_socks                      {'fox': 11, 'socks': 8, 'box': 3, 'knox': 8, '...\n",
              "hop_on_pop                        {'up': 4, 'pup': 7, 'is': 12, 'up.': 2, 'cup':...\n",
              "horton_hears_a_who                {'on': 17, 'the': 96, 'fifteenth': 1, 'of': 37...\n",
              "how_the_grinch_stole_christmas    {'every': 5, 'who': 10, 'down': 9, 'in': 15, '...\n",
              "oh_the_places_youll_go            {'congratulations!': 1, 'today': 2, 'is': 7, '...\n",
              "one_fish_two_fish                 {'one': 10, 'fish,': 7, 'two': 2, 'red': 1, 'b...\n",
              "dtype: object"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "bag_of_words = (\n",
        "    docs_seuss.\n",
        "    str.lower().                  # convert all letters to lowercase\n",
        "    str.replace(\"[^\\w\\s]\", \" \").  # replace non-alphanumeric characters by whitespace\n",
        "    str.split()                   # split on whitespace\n",
        ").apply(Counter)\n",
        "\n",
        "bag_of_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvgU4114b742"
      },
      "source": [
        "To turn this into a term-frequency matrix, we need to make a `DataFrame` out of it, where each column represents a word and each row a document---and each entry is the count of that word in the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ylxYncocb744"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>i</th>\n",
              "      <th>am</th>\n",
              "      <th>sam</th>\n",
              "      <th>that</th>\n",
              "      <th>sam-i-am</th>\n",
              "      <th>sam-i-am!</th>\n",
              "      <th>do</th>\n",
              "      <th>not</th>\n",
              "      <th>like</th>\n",
              "      <th>you</th>\n",
              "      <th>...</th>\n",
              "      <th>game?</th>\n",
              "      <th>gack</th>\n",
              "      <th>park</th>\n",
              "      <th>home,</th>\n",
              "      <th>clark.</th>\n",
              "      <th>grow</th>\n",
              "      <th>sleep</th>\n",
              "      <th>zeep.</th>\n",
              "      <th>gone.</th>\n",
              "      <th>one.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>65</td>\n",
              "      <td>44.0</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>37</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>43</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>48</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10</td>\n",
              "      <td>21.0</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 2264 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    i   am  sam  that  sam-i-am  sam-i-am!    do  not  like  you  ...  game?   \n",
              "0  71  3.0  3.0     3       4.0        2.0  35.0   65  44.0   21  ...    NaN  \\\n",
              "1  48  NaN  NaN    20       NaN        NaN  15.0   37  13.0   30  ...    NaN   \n",
              "2   9  NaN  NaN     1       NaN        NaN   7.0    1   1.0    7  ...    NaN   \n",
              "3   2  1.0  NaN     4       NaN        NaN   NaN    2   6.0    2  ...    NaN   \n",
              "4  18  1.0  NaN    31       NaN        NaN   1.0    6   NaN   27  ...    NaN   \n",
              "5   6  NaN  NaN    13       NaN        NaN   2.0    1   2.0    2  ...    NaN   \n",
              "6   2  NaN  NaN    11       NaN        NaN   4.0    6   1.0   43  ...    NaN   \n",
              "7  48  3.0  NaN     1       NaN        NaN  11.0   10  21.0   24  ...    1.0   \n",
              "\n",
              "   gack  park  home,  clark.  grow  sleep  zeep.  gone.  one.  \n",
              "0   NaN   NaN    NaN     NaN   NaN    NaN    NaN    NaN   NaN  \n",
              "1   NaN   NaN    NaN     NaN   NaN    NaN    NaN    NaN   NaN  \n",
              "2   NaN   NaN    NaN     NaN   NaN    NaN    NaN    NaN   NaN  \n",
              "3   NaN   NaN    NaN     NaN   NaN    NaN    NaN    NaN   NaN  \n",
              "4   NaN   NaN    NaN     NaN   NaN    NaN    NaN    NaN   NaN  \n",
              "5   NaN   NaN    NaN     NaN   NaN    NaN    NaN    NaN   NaN  \n",
              "6   NaN   NaN    NaN     NaN   NaN    NaN    NaN    NaN   NaN  \n",
              "7   1.0   1.0    1.0     1.0   1.0    2.0    1.0    1.0   1.0  \n",
              "\n",
              "[8 rows x 2264 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = pd.DataFrame(list(bag_of_words))\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAYV8ZPtb747"
      },
      "source": [
        "This matrix is full of missing numbers. A missing number means that the word did not appear in that document. In other words, a count of `NaN` really means a count of 0. So it makes sense in this situation to replace the `NaN`s by 0s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4p9mciwPb748"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>i</th>\n",
              "      <th>am</th>\n",
              "      <th>sam</th>\n",
              "      <th>that</th>\n",
              "      <th>sam-i-am</th>\n",
              "      <th>sam-i-am!</th>\n",
              "      <th>do</th>\n",
              "      <th>not</th>\n",
              "      <th>like</th>\n",
              "      <th>you</th>\n",
              "      <th>...</th>\n",
              "      <th>game?</th>\n",
              "      <th>gack</th>\n",
              "      <th>park</th>\n",
              "      <th>home,</th>\n",
              "      <th>clark.</th>\n",
              "      <th>grow</th>\n",
              "      <th>sleep</th>\n",
              "      <th>zeep.</th>\n",
              "      <th>gone.</th>\n",
              "      <th>one.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>65</td>\n",
              "      <td>44.0</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>37</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>43</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>48</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10</td>\n",
              "      <td>21.0</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 2264 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    i   am  sam  that  sam-i-am  sam-i-am!    do  not  like  you  ...  game?   \n",
              "0  71  3.0  3.0     3       4.0        2.0  35.0   65  44.0   21  ...    0.0  \\\n",
              "1  48  0.0  0.0    20       0.0        0.0  15.0   37  13.0   30  ...    0.0   \n",
              "2   9  0.0  0.0     1       0.0        0.0   7.0    1   1.0    7  ...    0.0   \n",
              "3   2  1.0  0.0     4       0.0        0.0   0.0    2   6.0    2  ...    0.0   \n",
              "4  18  1.0  0.0    31       0.0        0.0   1.0    6   0.0   27  ...    0.0   \n",
              "5   6  0.0  0.0    13       0.0        0.0   2.0    1   2.0    2  ...    0.0   \n",
              "6   2  0.0  0.0    11       0.0        0.0   4.0    6   1.0   43  ...    0.0   \n",
              "7  48  3.0  0.0     1       0.0        0.0  11.0   10  21.0   24  ...    1.0   \n",
              "\n",
              "   gack  park  home,  clark.  grow  sleep  zeep.  gone.  one.  \n",
              "0   0.0   0.0    0.0     0.0   0.0    0.0    0.0    0.0   0.0  \n",
              "1   0.0   0.0    0.0     0.0   0.0    0.0    0.0    0.0   0.0  \n",
              "2   0.0   0.0    0.0     0.0   0.0    0.0    0.0    0.0   0.0  \n",
              "3   0.0   0.0    0.0     0.0   0.0    0.0    0.0    0.0   0.0  \n",
              "4   0.0   0.0    0.0     0.0   0.0    0.0    0.0    0.0   0.0  \n",
              "5   0.0   0.0    0.0     0.0   0.0    0.0    0.0    0.0   0.0  \n",
              "6   0.0   0.0    0.0     0.0   0.0    0.0    0.0    0.0   0.0  \n",
              "7   1.0   1.0    1.0     1.0   1.0    2.0    1.0    1.0   1.0  \n",
              "\n",
              "[8 rows x 2264 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = tf.fillna(0)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbTiSkqNb75B"
      },
      "source": [
        "### Implementation using `scikit-learn`\n",
        "\n",
        "We could have also used the `CountVectorizer` in `scikit-learn` to obtain the term-frequency matrix. This vectorizer is fit to a list of the documents in the corpus. By default, it converts all letters to lowercase and strips punctuation, although this behavior can be customized using the `strip_accents=` and `lowercase=` parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fhl2Kwb5b75C"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<8x1344 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2308 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vec = CountVectorizer()\n",
        "vec.fit(docs_seuss) # This determines the vocabulary.\n",
        "tf_sparse = vec.transform(docs_seuss)\n",
        "\n",
        "tf_sparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ni61EAub75G"
      },
      "source": [
        "Notice that `CountVectorizer` returns the term-frequency matrix, not as a `DataFrame` or even as a `numpy` array, but as a `scipy` sparse matrix. A _sparse matrix_ is one whose entries are mostly zeroes. For example,\n",
        "\n",
        "$$ \\begin{pmatrix} 0 & 0 & 0 & 0 & 0 \\\\ 1.7 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & -0.8 & 0 \\end{pmatrix} $$\n",
        "\n",
        "is an example of a sparse matrix. Instead of storing 20 values (most of which are equal to 0), we can simply store the locations of the non-zero entries and their values:\n",
        "\n",
        "- $(1, 0) \\rightarrow 1.7$\n",
        "- $(3, 3) \\rightarrow -0.8$\n",
        "\n",
        "All other entries of the matrix are assumed to be zero. This representation offers substantial memory savings when there are only a few non-zero entries. (But if not, then this representation can actually be more expensive.) Term-frequency matrices are usually sparse because most words do not appear in all documents.\n",
        "\n",
        "The `scipy` sparse matrix format is used to store sparse matrices. If necessary, a `scipy` sparse matrix can be converted to a `numpy` matrix using the `.todense()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "61q9l5bbb75H"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 1, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 3, 1, 1]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_sparse.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibRYltDdb75L"
      },
      "source": [
        "We can further convert this `numpy` matrix to a `pandas` `DataFrame`. To make the column names descriptive, we call the `.get_feature_names_out()` method of the `CountVectorizer`, which returns a list of the words in the order that they appear in the matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NKAtlcEDb75M"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>12</th>\n",
              "      <th>56</th>\n",
              "      <th>98</th>\n",
              "      <th>able</th>\n",
              "      <th>about</th>\n",
              "      <th>act</th>\n",
              "      <th>afraid</th>\n",
              "      <th>after</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>again</th>\n",
              "      <th>...</th>\n",
              "      <th>yop</th>\n",
              "      <th>yopp</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>yourselves</th>\n",
              "      <th>zans</th>\n",
              "      <th>zeds</th>\n",
              "      <th>zeep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>47</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1344 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   12  56  98  able  about  act  afraid  after  afternoon  again  ...  yop   \n",
              "0   0   0   0     0      0    0       0      0          0      0  ...    0  \\\n",
              "1   0   0   0     0      3    0       0      1          0      0  ...    0   \n",
              "2   0   0   0     0      2    0       0      0          0      0  ...    0   \n",
              "3   0   0   0     0      0    0       0      2          0      0  ...    0   \n",
              "4   1   1   0     1      1    0       0      4          2      1  ...    0   \n",
              "5   0   0   0     0      0    0       0      0          0      0  ...    0   \n",
              "6   0   0   1     0      1    1       2      0          0      0  ...    0   \n",
              "7   0   0   0     0      1    0       0      0          0      2  ...    1   \n",
              "\n",
              "   yopp  you  young  your  yourself  yourselves  zans  zeds  zeep  \n",
              "0     0   34      0     0         0           0     0     0     0  \n",
              "1     0   34      0     8         0           0     0     0     0  \n",
              "2     0    8      0     1         0           0     0     0     0  \n",
              "3     0    2      0     0         0           0     0     0     0  \n",
              "4     3   47      5     7         0           1     0     0     0  \n",
              "5     0    2      1     0         0           0     0     0     0  \n",
              "6     0   85      0    20         2           0     0     0     0  \n",
              "7     0   24      0     9         0           0     3     1     1  \n",
              "\n",
              "[8 rows x 1344 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(\n",
        "    tf_sparse.todense(),\n",
        "    columns=vec.get_feature_names_out()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnompYDTb75P"
      },
      "source": [
        "The term-frequency matrix that `CountVectorizer` produced is not exactly the same as the matrix that we produced ourselves using just `pandas`. Although the two matrices have the same number of rows (8, corresponding to the number of documents in the corpus), they have a different number of columns. It appears that `CountVectorizer` had a vocabulary that was 11 words smaller (1344 words instead of 1355). We can determine exactly which 11 words these are, by taking the set difference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IK31TXDvb75Q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'yipping!',\n",
              " 'grinch.',\n",
              " 'still.',\n",
              " 'things.\"',\n",
              " \"i've\",\n",
              " 'christmas!',\n",
              " 'gump.',\n",
              " 'you!\"',\n",
              " 'whos,',\n",
              " 'oh!',\n",
              " 'roof,',\n",
              " 'win?',\n",
              " 'broom.',\n",
              " 'brown?',\n",
              " 'dope!',\n",
              " 'so...',\n",
              " 'packages,',\n",
              " 'you,\"',\n",
              " 'say?',\n",
              " 'fun?',\n",
              " 'sacks,',\n",
              " 'joys...',\n",
              " '\"and',\n",
              " 'headed,',\n",
              " 'know,',\n",
              " 'kettles!',\n",
              " 'nonsense!',\n",
              " 'pop.',\n",
              " 'small,',\n",
              " 'shirking?\"',\n",
              " 'trick,',\n",
              " '\"if',\n",
              " 'sally.',\n",
              " 'pink.',\n",
              " 'all!\"',\n",
              " 'there.',\n",
              " 'net,',\n",
              " 'around.\"',\n",
              " 'liar.',\n",
              " 'bones,',\n",
              " 'talking!',\n",
              " 'marked.',\n",
              " 'night.he',\n",
              " 'so!',\n",
              " 'nose.',\n",
              " 'loudly.',\n",
              " 'now.',\n",
              " 'why:',\n",
              " 'said...',\n",
              " 'funny!\"',\n",
              " 'yell.',\n",
              " 'down,',\n",
              " 'claus,',\n",
              " 'tinsel!',\n",
              " 'nick!\"',\n",
              " 'near?',\n",
              " 'i',\n",
              " 'brush!',\n",
              " 'succeed?',\n",
              " \"ben's\",\n",
              " 'out?',\n",
              " 'darked.',\n",
              " \"mother's\",\n",
              " 'heights.',\n",
              " 'bicycles!',\n",
              " '\"boil',\n",
              " 'hour!',\n",
              " 'bit!\"',\n",
              " 'town,',\n",
              " \"trees'\",\n",
              " 'then?',\n",
              " '\"there\\'s',\n",
              " 'done.',\n",
              " 'side.\"',\n",
              " \"horton's\",\n",
              " 'you.',\n",
              " 'be.',\n",
              " 'how?\"',\n",
              " 'said.',\n",
              " 'step.',\n",
              " 'blocks.',\n",
              " 'chewing!',\n",
              " 'bed.',\n",
              " 'safe,',\n",
              " 'lighted.',\n",
              " 'now!',\n",
              " 'so...get',\n",
              " 'town.',\n",
              " 'trees.',\n",
              " 'cow?',\n",
              " 'me,',\n",
              " '\"me,',\n",
              " 'heads.',\n",
              " 'wish,',\n",
              " 'minute,',\n",
              " 'look,',\n",
              " 'go.',\n",
              " 'gown!',\n",
              " 'kangaroo.',\n",
              " 'grow.',\n",
              " 'try!\"',\n",
              " 'call...',\n",
              " 'fan!',\n",
              " 'groans,',\n",
              " 'curls,',\n",
              " 'sights!',\n",
              " 'working?',\n",
              " 'coming!\"',\n",
              " 'they.\"',\n",
              " 'dropped,',\n",
              " 'fat.',\n",
              " 'walking.',\n",
              " 'around.',\n",
              " 'sneeze.',\n",
              " 'ball!',\n",
              " 'zeep.',\n",
              " 'yet!\"',\n",
              " 'pool.',\n",
              " '\"of',\n",
              " 'least!',\n",
              " 'go,',\n",
              " '\"believe',\n",
              " 'ringing.',\n",
              " 'eyes...',\n",
              " 'growled,',\n",
              " 'noise,\"',\n",
              " 'thump!',\n",
              " 'strong,',\n",
              " 'rot!',\n",
              " \"crow's\",\n",
              " 'shouting,',\n",
              " 'town!',\n",
              " '\"now',\n",
              " 'hullabaloo:',\n",
              " 'whos!\"',\n",
              " 'fast.',\n",
              " 'clothes?',\n",
              " 'standing,',\n",
              " 'hands.',\n",
              " 'fine.',\n",
              " '\"and,',\n",
              " 'fear,',\n",
              " 'ham.',\n",
              " 'twerp!',\n",
              " 'stockings,\"',\n",
              " 'along.',\n",
              " 'foul.',\n",
              " 'so?\"',\n",
              " 'way!\"',\n",
              " 'sing!',\n",
              " 'sun.',\n",
              " 'good-by,',\n",
              " 'yo-yo!',\n",
              " 'oh,',\n",
              " 'roar!',\n",
              " 'sir?',\n",
              " 'toys!',\n",
              " 'head?',\n",
              " 'well?\"',\n",
              " 'books!',\n",
              " '\"your',\n",
              " 'indeed!',\n",
              " 'sit!',\n",
              " 'dark!',\n",
              " 'too!',\n",
              " 'from?',\n",
              " 'lot...',\n",
              " '\"these',\n",
              " 'surprise!',\n",
              " 'it,',\n",
              " 'everywhere.',\n",
              " 'stop.',\n",
              " 'mike,',\n",
              " 'eve,',\n",
              " 'tocks,',\n",
              " 'glad.',\n",
              " 'train.',\n",
              " 'came!',\n",
              " 'hill.',\n",
              " 'rake!',\n",
              " 'store.\"',\n",
              " 'ring,',\n",
              " 'left.',\n",
              " 'slow,',\n",
              " 'this?\"',\n",
              " 'chimney.',\n",
              " 'train?',\n",
              " \"isn't\",\n",
              " 'well.',\n",
              " 'sir,',\n",
              " 'reason.',\n",
              " 'ship!',\n",
              " 'rain.',\n",
              " 'fall!\"',\n",
              " 'day,',\n",
              " 'other,',\n",
              " 'goat.',\n",
              " 'tricks,\"',\n",
              " 'alone,',\n",
              " 'splashing.',\n",
              " 'yell,',\n",
              " 'daughter,',\n",
              " 'bust!',\n",
              " 'he,',\n",
              " 'too?\"',\n",
              " 'tall,',\n",
              " 'anywhere.',\n",
              " 'fall!',\n",
              " 'speak,',\n",
              " 'ribbons!',\n",
              " 'sadly,',\n",
              " 'doing.',\n",
              " 'bet,',\n",
              " 'be?',\n",
              " 'flue.',\n",
              " 'near!',\n",
              " '\"no!',\n",
              " '\"so,',\n",
              " 'words,',\n",
              " \"who'll\",\n",
              " 'us?',\n",
              " \"we'll\",\n",
              " 'un-slumping',\n",
              " 'sky.',\n",
              " 'cage!',\n",
              " 'voice,',\n",
              " 'amounts!',\n",
              " 'early.',\n",
              " '\"humpf!\"',\n",
              " 'mr.',\n",
              " 'course,\"',\n",
              " 'yes!',\n",
              " 'thing?',\n",
              " 'looked.',\n",
              " 'bad?',\n",
              " 'dust!\"',\n",
              " '(98',\n",
              " 'could,',\n",
              " \"couldn't\",\n",
              " 'six,',\n",
              " 'say,',\n",
              " 'hop?',\n",
              " 'frown,',\n",
              " 'that.\"',\n",
              " 'pin.',\n",
              " 'tame!',\n",
              " 'fall-ish,',\n",
              " 'mother!',\n",
              " 'pot.',\n",
              " 'thought,',\n",
              " 'do.\"',\n",
              " '\"pooh-pooh',\n",
              " 'bat.',\n",
              " 'quick!',\n",
              " 'snow,',\n",
              " 'fox.',\n",
              " 'them!',\n",
              " 'home,',\n",
              " 'hat.',\n",
              " 'sound.',\n",
              " '(apartment',\n",
              " 'jo-jo',\n",
              " 'sam-i-am!',\n",
              " 'house.',\n",
              " \"hadn't\",\n",
              " 'right.',\n",
              " 'ned.',\n",
              " '\"is',\n",
              " 'two,',\n",
              " 'did!\"',\n",
              " 'popcorn!',\n",
              " 'lakes.',\n",
              " 'yes,\"',\n",
              " 'something!',\n",
              " 'tree,',\n",
              " 'alone!',\n",
              " '\"you',\n",
              " 'flip-flapping,',\n",
              " 'blubber!',\n",
              " 'done!',\n",
              " 'mean?...',\n",
              " '\"i\\'ve',\n",
              " 'it!',\n",
              " 'sound?',\n",
              " 'cake!',\n",
              " 'been!\"',\n",
              " '...',\n",
              " '\"why,',\n",
              " 'books,',\n",
              " 'hello.',\n",
              " 'yes,',\n",
              " 'clocks,',\n",
              " 'wrappings!',\n",
              " 'goo,',\n",
              " 'away!',\n",
              " 'juice!\"',\n",
              " 'kites,\"',\n",
              " \"person's\",\n",
              " 'floor-to-floor!',\n",
              " 'now....',\n",
              " 'him,',\n",
              " \"luke's\",\n",
              " 'pup.',\n",
              " 'lurch.',\n",
              " 'jump!',\n",
              " 'and...',\n",
              " 'best.',\n",
              " 'all,',\n",
              " 'dear!\"',\n",
              " 'like,\"',\n",
              " 'small.',\n",
              " 'lit.',\n",
              " \"i'm\",\n",
              " '\"i\\'ll',\n",
              " '\"please',\n",
              " 'crumpit,',\n",
              " '\"should',\n",
              " 'think?...why,',\n",
              " 'four.',\n",
              " '\"maybe',\n",
              " 'flutes!',\n",
              " 'bike.',\n",
              " 'black-bottomed',\n",
              " 'good-by!',\n",
              " \"we've\",\n",
              " 'brother.',\n",
              " 'house?',\n",
              " 'old,',\n",
              " 'sleep.',\n",
              " 'wump.',\n",
              " 'comb!',\n",
              " 'flower!\"',\n",
              " 'me!',\n",
              " 'do!\"',\n",
              " 'picked,',\n",
              " 'dad.',\n",
              " 'nowhere,',\n",
              " '\"quit',\n",
              " '\"my',\n",
              " '\"a',\n",
              " 'see.',\n",
              " 'christmas...perhaps...means',\n",
              " 'small-ish!\"',\n",
              " 'goes.',\n",
              " 'end.',\n",
              " 'and,',\n",
              " 'knox....',\n",
              " 'splashing...enjoying',\n",
              " 'care,',\n",
              " 'rest.',\n",
              " 'begged,',\n",
              " 'buildings,',\n",
              " 'tight.',\n",
              " 'behind?',\n",
              " 'noise?',\n",
              " 'sam!',\n",
              " 'out.',\n",
              " 'be.\"',\n",
              " 'breeze,',\n",
              " 'tomorrow,',\n",
              " 'find,',\n",
              " 'do?\"',\n",
              " 'well...',\n",
              " 'sir!',\n",
              " 'perhaps,',\n",
              " 'neck!',\n",
              " 'heard!',\n",
              " 'mouses!',\n",
              " '\"for',\n",
              " 'likely...',\n",
              " \"he's\",\n",
              " 'down!\"',\n",
              " 'too,',\n",
              " 'blue.',\n",
              " 'hat!',\n",
              " 'speck...hah!',\n",
              " 'summer.',\n",
              " 'read,',\n",
              " 'last!',\n",
              " 'bee.',\n",
              " '\"all',\n",
              " 'sorry,',\n",
              " '\"take',\n",
              " 'more!\"',\n",
              " 'cans!',\n",
              " 'but,',\n",
              " 'same!',\n",
              " 'elephant.',\n",
              " 'slump.',\n",
              " '\"find',\n",
              " 'here.\"',\n",
              " 'air.',\n",
              " 'present!',\n",
              " 'things,\"',\n",
              " 'knox,',\n",
              " 'band!',\n",
              " 'well.\"',\n",
              " 'in-laws,',\n",
              " 'snow.',\n",
              " 'no!',\n",
              " 'stew.',\n",
              " 'bell.',\n",
              " 'fool!\"',\n",
              " 'sam-i-am.',\n",
              " '\"how',\n",
              " \"'em\",\n",
              " 'square.',\n",
              " 'cow,',\n",
              " 'state,\"',\n",
              " 'right-and-three-quarters?',\n",
              " 'ink.',\n",
              " 'a-bed,',\n",
              " 'not,',\n",
              " 'mouth,',\n",
              " 'song.',\n",
              " 'wire.',\n",
              " 'box?',\n",
              " 'noodle-eating',\n",
              " 'long,',\n",
              " '\"this,\"',\n",
              " 'do,',\n",
              " 'muddle.',\n",
              " 'her.',\n",
              " 'beak.',\n",
              " '\"what',\n",
              " 'fun.\"',\n",
              " '\"so',\n",
              " 'wall.',\n",
              " 'play.',\n",
              " 'space,',\n",
              " 'please,\"',\n",
              " 'bird.',\n",
              " 'brown!',\n",
              " '\"we\\'ve',\n",
              " 'then,',\n",
              " 'mrs.',\n",
              " 'reindeer...\"',\n",
              " '...for',\n",
              " 'fun-in-a-box,\"',\n",
              " 'this?',\n",
              " 'slunk,',\n",
              " 'speck-voice',\n",
              " 'down?...\"',\n",
              " 'merry!',\n",
              " 'know.',\n",
              " 'rake,',\n",
              " 'sore.',\n",
              " 'drumming,',\n",
              " 'five.',\n",
              " 'stack.',\n",
              " 'icebox.',\n",
              " 'mouse?',\n",
              " 'shame!',\n",
              " \"won't.\",\n",
              " 'fox!',\n",
              " '\"we',\n",
              " 'pans,',\n",
              " 'on,',\n",
              " 'down.',\n",
              " 'goat!',\n",
              " 'hear?',\n",
              " 'sir....',\n",
              " 'say....',\n",
              " 'feast!',\n",
              " \"you've\",\n",
              " 'there,',\n",
              " 'can,',\n",
              " 'them.',\n",
              " 'coming!',\n",
              " 'tom-tom.',\n",
              " 'old.',\n",
              " 'who!',\n",
              " 'me,\"',\n",
              " 'in,',\n",
              " 'may.',\n",
              " 'splashing!\"',\n",
              " '\"...me,',\n",
              " 'mayor,',\n",
              " 'max.',\n",
              " 'day!',\n",
              " 'clucked,',\n",
              " 'flew,',\n",
              " 'are.',\n",
              " 'eagle,',\n",
              " 'thread,',\n",
              " \"elephant's\",\n",
              " 'up-up-up',\n",
              " 'brooms.',\n",
              " '\"oh,',\n",
              " 'rocking-chairs',\n",
              " 'do!',\n",
              " 'so,\"',\n",
              " 'high!',\n",
              " 'bipping!',\n",
              " 'through!\"',\n",
              " 'call.',\n",
              " \"what's\",\n",
              " '\"yopp!\"',\n",
              " 'wet,',\n",
              " 'that!',\n",
              " 'friend.',\n",
              " 'crashed.',\n",
              " 'bad,\"',\n",
              " '\"from',\n",
              " 'boat.',\n",
              " 'will,',\n",
              " '\"are',\n",
              " 'heard,\"',\n",
              " 'up,',\n",
              " 'think.',\n",
              " 'dust!',\n",
              " 'tock.',\n",
              " 'true!',\n",
              " 'fist.',\n",
              " 'boat?',\n",
              " 'friend,\"',\n",
              " 'him!',\n",
              " 'sad.',\n",
              " 'fish!',\n",
              " 'back.',\n",
              " 'say!\"',\n",
              " 'through.',\n",
              " 'away.',\n",
              " 'there!',\n",
              " 'best?',\n",
              " \"bim's\",\n",
              " 'said,',\n",
              " 'hop,',\n",
              " 'it.',\n",
              " 'yon,',\n",
              " 'be,',\n",
              " 'steer!',\n",
              " 'far-distant',\n",
              " \"didn't\",\n",
              " 'quite,',\n",
              " '\"do',\n",
              " 'quite?',\n",
              " 'are,',\n",
              " 'counts!\"',\n",
              " 'up!',\n",
              " 'red,',\n",
              " 'car!',\n",
              " 'do...',\n",
              " \"they'll\",\n",
              " 'easy,',\n",
              " 'you?',\n",
              " 'far.',\n",
              " 'sunny.',\n",
              " 'sincerely,',\n",
              " 'run.',\n",
              " 'over!',\n",
              " 'man!',\n",
              " 'three.',\n",
              " \"you're\",\n",
              " '\"tomorrow',\n",
              " 'alarm.',\n",
              " 'fail.\"',\n",
              " 'persons,',\n",
              " \"life's\",\n",
              " 'hop!',\n",
              " \"bottle's\",\n",
              " 'say.',\n",
              " 'goo-goose',\n",
              " 'all!',\n",
              " 'mean...\"',\n",
              " 'today.',\n",
              " 'bet.',\n",
              " \"poodle's\",\n",
              " '\"have',\n",
              " '\"as',\n",
              " 'some,',\n",
              " 'nool!\"',\n",
              " 'tree.',\n",
              " 'band.',\n",
              " 'together,',\n",
              " 'feast.',\n",
              " 'pinch.',\n",
              " 'puzzling:',\n",
              " 'walk.',\n",
              " 'small!',\n",
              " 'searched,',\n",
              " 'clover,',\n",
              " 'chimney,',\n",
              " 'beetles?',\n",
              " 'all...',\n",
              " 'sky!',\n",
              " 'comb.',\n",
              " 'again.',\n",
              " 'chimney!',\n",
              " 'bad,',\n",
              " 'star.',\n",
              " 'fear.',\n",
              " '\"...a',\n",
              " 'where?\"',\n",
              " 'thing.',\n",
              " \"don'\",\n",
              " 'clark.',\n",
              " 'tags!\"',\n",
              " 'here.',\n",
              " 'fox,',\n",
              " 'why.',\n",
              " 'there?',\n",
              " 'cat...',\n",
              " 'anything.',\n",
              " 'cake,',\n",
              " 'thing?\"',\n",
              " 'cold.',\n",
              " 'speed.',\n",
              " 'slow.',\n",
              " 'eleven!',\n",
              " 'finally,',\n",
              " 'net.',\n",
              " 'stew!\"',\n",
              " 'hours,',\n",
              " 'west.',\n",
              " \"who've\",\n",
              " 'comb,',\n",
              " 'car?',\n",
              " 'drowned!',\n",
              " 'thing!',\n",
              " 'flew.',\n",
              " 'the,',\n",
              " 'or,',\n",
              " 'head!',\n",
              " 'how.',\n",
              " 'slick,',\n",
              " 'after,',\n",
              " 'boo-hoo!\"',\n",
              " 'voice!',\n",
              " 'grows.',\n",
              " 'who-ville',\n",
              " 'top,',\n",
              " 'do.',\n",
              " 'not-so-good',\n",
              " 'noise.',\n",
              " 'drums!',\n",
              " '\"was',\n",
              " 'eight,',\n",
              " \"you'll\",\n",
              " 'wide!',\n",
              " 'trappings!',\n",
              " \"he'll\",\n",
              " 'tall.',\n",
              " 'go!\"',\n",
              " 'two?\"',\n",
              " 'jungle!',\n",
              " 'tight,',\n",
              " 'hated!',\n",
              " 'come.',\n",
              " 'scream!',\n",
              " 'gack.',\n",
              " 'ten.',\n",
              " 'rubber.',\n",
              " 'wing,',\n",
              " \"whos'\",\n",
              " 'tent.',\n",
              " 'jumped.',\n",
              " 'horton,',\n",
              " 'look.',\n",
              " 'flower!',\n",
              " 'him!\"',\n",
              " 'stopped.',\n",
              " 'prowl.',\n",
              " 'very,',\n",
              " 'very!',\n",
              " 'row.',\n",
              " 'up.',\n",
              " 'far,',\n",
              " 'climbed.',\n",
              " 'too!\"',\n",
              " 'gold.',\n",
              " 'lose!',\n",
              " \"that's\",\n",
              " 'oil!\"',\n",
              " 'child.',\n",
              " 'yes.',\n",
              " 'black.',\n",
              " 'cake.',\n",
              " 'pet?',\n",
              " 'bags,',\n",
              " 'clothes.',\n",
              " 'tower.',\n",
              " 'wonderful,',\n",
              " 'one.',\n",
              " 'shame,',\n",
              " 'look!\"',\n",
              " 'off.',\n",
              " 'boil,',\n",
              " 'now,',\n",
              " 'sled,',\n",
              " '\"did',\n",
              " 'if,',\n",
              " 'who-roast',\n",
              " 'himself!',\n",
              " 'tricycles!',\n",
              " 'worrying,',\n",
              " 'blew.',\n",
              " 'why?\"',\n",
              " 'wet.',\n",
              " 'fire!',\n",
              " 'stockings!\"',\n",
              " 'dear!',\n",
              " \"it's\",\n",
              " 'pink,',\n",
              " 'mouse.',\n",
              " 'zans.',\n",
              " 'vlad-i-koff,',\n",
              " 'mayor:',\n",
              " '\"in',\n",
              " 'nool,',\n",
              " 'pants.',\n",
              " 'good,\"',\n",
              " 'yipp!',\n",
              " 'one!',\n",
              " 'again!',\n",
              " 'humming.',\n",
              " 'here!\"',\n",
              " 'fight,',\n",
              " 'prickle-ly',\n",
              " 'fish,\"',\n",
              " 'game,',\n",
              " 'puddle,',\n",
              " 'here,',\n",
              " 'done,',\n",
              " 'choose.',\n",
              " 'fame!',\n",
              " 'head,',\n",
              " '\"that',\n",
              " 'thick!\"',\n",
              " '\"you\\'re',\n",
              " 'pot!',\n",
              " 'coat.',\n",
              " 'did,',\n",
              " 'no.',\n",
              " \"won't\",\n",
              " '\"will',\n",
              " 'two!\"',\n",
              " 'bags.',\n",
              " 'gooey.',\n",
              " 'too.',\n",
              " 'winning-est',\n",
              " 'who-pudding!',\n",
              " 'creek,',\n",
              " 'bungle!',\n",
              " 'gasped,',\n",
              " 'act.',\n",
              " 'yopp...',\n",
              " 'clover!',\n",
              " 'sound!',\n",
              " 'hour.',\n",
              " 'throat.',\n",
              " 'share.',\n",
              " 'size,',\n",
              " 'idea!',\n",
              " '\"no,',\n",
              " 'course,',\n",
              " '\"santy',\n",
              " 'should.',\n",
              " 'all....\"',\n",
              " 'why,',\n",
              " 'hall.',\n",
              " 'floors.',\n",
              " 'nook.',\n",
              " 'mess,\"',\n",
              " 'ham!',\n",
              " '\"their',\n",
              " 'tv.',\n",
              " \"here's\",\n",
              " 'boat!',\n",
              " 'strings,',\n",
              " 'it!\"',\n",
              " 'caged!',\n",
              " 'fox?',\n",
              " 'true,\"',\n",
              " 'zeds.',\n",
              " '\"why',\n",
              " 'happen,',\n",
              " 'guns!',\n",
              " 'feet,',\n",
              " 'grinch?',\n",
              " 'family,',\n",
              " 'blocks,',\n",
              " 'cindy-lou',\n",
              " 'way.',\n",
              " 'dish,',\n",
              " 'friends!\"',\n",
              " 'place...',\n",
              " 'flight,',\n",
              " 'chance.',\n",
              " 'repairs?\"',\n",
              " 'pool!',\n",
              " 'sam,',\n",
              " 'workshop,',\n",
              " 'say!',\n",
              " 'streets.',\n",
              " 'battle.',\n",
              " 'whos!',\n",
              " 'glee.',\n",
              " 'fish!\"',\n",
              " 'new.',\n",
              " '\"he',\n",
              " 'tell!',\n",
              " 'plop!',\n",
              " 'dear.\"',\n",
              " 'game,\"',\n",
              " 'nimbly,',\n",
              " 'either.\"',\n",
              " 'red.',\n",
              " 'know!\"',\n",
              " 'rain?',\n",
              " 'bumped.',\n",
              " 'gently,',\n",
              " 'house!',\n",
              " '\"but',\n",
              " 'now!\"',\n",
              " 'safe?',\n",
              " 'on.',\n",
              " 'ear.',\n",
              " 'milk,',\n",
              " 'fish,',\n",
              " '...they',\n",
              " 'clearly.',\n",
              " 'see!',\n",
              " 'cans.',\n",
              " 'star,',\n",
              " 'do?...',\n",
              " '3/4',\n",
              " 'fear!\"',\n",
              " 'may,',\n",
              " 'bends.',\n",
              " 'mayor!\"',\n",
              " 'ink,',\n",
              " 'ball.',\n",
              " 'told.',\n",
              " 'fifty-three',\n",
              " 'anywhere!',\n",
              " \"o'shea,\",\n",
              " 'country!\"',\n",
              " 'play,\"',\n",
              " 'hot,',\n",
              " 'dish!',\n",
              " 'ice-cold',\n",
              " 'long.',\n",
              " 'mt.',\n",
              " 'yapping.',\n",
              " 'own.',\n",
              " 'house!\"',\n",
              " 'bands.',\n",
              " \"can't\",\n",
              " '\"they\\'re',\n",
              " 'case,',\n",
              " 'leak.',\n",
              " 'booms.',\n",
              " 'hissed,',\n",
              " 'low.',\n",
              " 'shine.',\n",
              " 'day.\"',\n",
              " 'freeze.',\n",
              " \"won't!\",\n",
              " 'yink.',\n",
              " '\"with',\n",
              " 'oom-pahs',\n",
              " 'pat.',\n",
              " 'who-christmas-sing,',\n",
              " \"grinch's\",\n",
              " 'voice.',\n",
              " 'there?\"',\n",
              " 'voices.',\n",
              " 'book.',\n",
              " 'hat,',\n",
              " 'chew,',\n",
              " 'maybe,',\n",
              " 'eyes!',\n",
              " 'engaged,',\n",
              " 'waiting,',\n",
              " 'sad!',\n",
              " 'then!',\n",
              " 'out!\"',\n",
              " 'three,',\n",
              " 'whoville,',\n",
              " 'i?',\n",
              " \"don't\",\n",
              " '\"they',\n",
              " 'bow.',\n",
              " 'not!',\n",
              " 'answered.',\n",
              " 'season!',\n",
              " 't',\n",
              " 'four,',\n",
              " 'carryings-on',\n",
              " 'dish.',\n",
              " 'tail.',\n",
              " \"aren't\",\n",
              " 'wump?',\n",
              " 'neither.\"',\n",
              " 'kid,',\n",
              " 'guaranteed.)',\n",
              " \"let's\",\n",
              " 'please!\"',\n",
              " 'look!',\n",
              " 'there!\"',\n",
              " 'hand!',\n",
              " 'wall!',\n",
              " 'smiled.',\n",
              " 'cat!',\n",
              " '\"i',\n",
              " 'hike,',\n",
              " 'drink,',\n",
              " 'noise!',\n",
              " 'walked,',\n",
              " 'chuckled,',\n",
              " 'well,',\n",
              " 'away!\"',\n",
              " \"they'd\",\n",
              " 'dove.',\n",
              " 'don’t',\n",
              " 'moon,',\n",
              " '\"doesn\\'t',\n",
              " 'kangaroo,',\n",
              " 'yink,',\n",
              " 'person.',\n",
              " 'sheep.',\n",
              " 'goat?',\n",
              " 'houses,',\n",
              " 'it?...\"',\n",
              " 'tops,',\n",
              " 'nine,',\n",
              " \"jungle's\",\n",
              " \"they've\",\n",
              " 'home!',\n",
              " 'care.',\n",
              " 'dog,',\n",
              " 'dawn...',\n",
              " 'beast!',\n",
              " 'slump,',\n",
              " 'not.',\n",
              " 'holler!',\n",
              " 'perch.',\n",
              " \"'cause\",\n",
              " 'horton!',\n",
              " 'thing!\"',\n",
              " 'places!',\n",
              " 'game...',\n",
              " 'us,',\n",
              " \"they're\",\n",
              " 'about.',\n",
              " 'whoville!',\n",
              " 'please,',\n",
              " 'small.\"',\n",
              " 'flash.',\n",
              " 'plums!',\n",
              " 'fish.',\n",
              " 'whole?',\n",
              " '\"i\\'m',\n",
              " 'gluey.',\n",
              " 'horton.',\n",
              " 'bottle...',\n",
              " 'talk.',\n",
              " 'out,',\n",
              " 'mine.',\n",
              " 'scarce,',\n",
              " '\"that\\'s',\n",
              " 'meeting.',\n",
              " 'alive,',\n",
              " 'tot,\"',\n",
              " 'comes.',\n",
              " 'good.',\n",
              " 'bang-ups',\n",
              " 'mother.',\n",
              " 'worry.',\n",
              " 'pearls,',\n",
              " 'one,\"',\n",
              " 'mat!',\n",
              " 'lot!\"',\n",
              " 'fingers!',\n",
              " 'that?\"',\n",
              " 'ship,',\n",
              " 'gone.',\n",
              " 'hook.',\n",
              " 'tree?',\n",
              " 'down.\"',\n",
              " 'so,',\n",
              " 'well...in',\n",
              " 'bed?',\n",
              " 'hear!\"',\n",
              " 'paused.',\n",
              " 'shame!\"',\n",
              " 'three...',\n",
              " 'here!',\n",
              " 'poodle,',\n",
              " 'house,',\n",
              " 'new?',\n",
              " 'lad!',\n",
              " 'right...',\n",
              " 'instead!\"',\n",
              " 'trimmings!',\n",
              " 'rake.',\n",
              " 'goo-goose,',\n",
              " 'first,',\n",
              " 'deft.',\n",
              " ...}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(tf.columns) - set(vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tF1gsPqb75U"
      },
      "source": [
        "We see that all of the words that `CountVectorizer` missed were one-character long. By default, `CountVectorizer` only retains words that are at least 2 characters long. This behavior can be customized using regular expressions in the `token_pattern=` parameter. (By default, scikit-Learn strips punctuation and\n",
        "converts all characters to lowercase, but you can also customize that behavior using `token_pattern`.) However, since 1-letter words are usually not useful for analysis anyway, this is a minor technical point. We won't cover regular expressions in any detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TvlzDn5cN7N5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<8x1355 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2345 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vec = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "vec.fit(docs_seuss) # This determines the vocabulary.\n",
        "tf_sparse = vec.transform(docs_seuss)\n",
        "\n",
        "tf_sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EpH2QmCHQNX1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    16\n",
              "1     0\n",
              "2     0\n",
              "3     1\n",
              "4     1\n",
              "5     0\n",
              "6     0\n",
              "7     3\n",
              "Name: am, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(\n",
        "    tf_sparse.todense(),\n",
        "    columns=vec.get_feature_names_out()\n",
        ")[\"am\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zXEH9FDJu8u"
      },
      "source": [
        "`CountVectorizer` can even count $n$-grams by specify `ngram_range`. If we wanted bigrams, then we would specify `ngram_range=(2, 2)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZupRCUkpJwsh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<8x5846 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 6459 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(2, 2))\n",
        "vec.fit(docs_seuss)\n",
        "tf_sparse_bigram = vec.transform(docs_seuss)\n",
        "\n",
        "tf_sparse_bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jutdlxAjKqZ2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>12 very</th>\n",
              "      <th>56 the</th>\n",
              "      <th>98 and</th>\n",
              "      <th>able to</th>\n",
              "      <th>about he</th>\n",
              "      <th>about it</th>\n",
              "      <th>about some</th>\n",
              "      <th>about to</th>\n",
              "      <th>about tweetle</th>\n",
              "      <th>about when</th>\n",
              "      <th>...</th>\n",
              "      <th>your towns</th>\n",
              "      <th>your way</th>\n",
              "      <th>your yapping</th>\n",
              "      <th>yourself any</th>\n",
              "      <th>yourself is</th>\n",
              "      <th>yourselves heard</th>\n",
              "      <th>zans for</th>\n",
              "      <th>zans zans</th>\n",
              "      <th>zeds they</th>\n",
              "      <th>zeep today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 5846 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   12 very  56 the  98 and  able to  about he  about it  about some  about to   \n",
              "0        0       0       0        0         0         0           0         0  \\\n",
              "1        0       0       0        0         1         1           0         0   \n",
              "2        0       0       0        0         0         0           0         0   \n",
              "3        0       0       0        0         0         0           0         0   \n",
              "4        1       1       0        1         0         0           0         1   \n",
              "5        0       0       0        0         0         0           0         0   \n",
              "6        0       0       1        0         0         0           1         0   \n",
              "7        0       0       0        0         0         0           0         0   \n",
              "\n",
              "   about tweetle  about when  ...  your towns  your way  your yapping   \n",
              "0              0           0  ...           0         0             0  \\\n",
              "1              0           0  ...           0         0             0   \n",
              "2              2           0  ...           0         0             0   \n",
              "3              0           0  ...           0         0             0   \n",
              "4              0           0  ...           1         0             1   \n",
              "5              0           0  ...           0         0             0   \n",
              "6              0           0  ...           0         2             0   \n",
              "7              0           1  ...           0         0             0   \n",
              "\n",
              "   yourself any  yourself is  yourselves heard  zans for  zans zans   \n",
              "0             0            0                 0         0          0  \\\n",
              "1             0            0                 0         0          0   \n",
              "2             0            0                 0         0          0   \n",
              "3             0            0                 0         0          0   \n",
              "4             0            0                 1         0          0   \n",
              "5             0            0                 0         0          0   \n",
              "6             1            1                 0         0          0   \n",
              "7             0            0                 0         2          1   \n",
              "\n",
              "   zeds they  zeep today  \n",
              "0          0           0  \n",
              "1          0           0  \n",
              "2          0           0  \n",
              "3          0           0  \n",
              "4          0           0  \n",
              "5          0           0  \n",
              "6          0           0  \n",
              "7          1           1  \n",
              "\n",
              "[8 rows x 5846 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(\n",
        "    tf_sparse_bigram.todense(),\n",
        "    columns=vec.get_feature_names_out()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYCZ57PTKsNf"
      },
      "source": [
        "Note that there are about 5800 bigrams. A data frame with 8 rows and 5800 columns has around 50000 entries. However, only about 6500 of these entries are non-zero. This is why sparse matrices are vital in text processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MaTqOVuQJzTm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6459"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of non-zero values in the sparse matrix.\n",
        "tf_sparse_bigram.count_nonzero()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Pt4YzPb75V"
      },
      "source": [
        "If we wanted unigrams (i.e., individual words), bigrams, and trigrams then we would specify `ngram_range=(1, 3)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xXPmH0rPb75W"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<8x14918 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 16560 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 3))\n",
        "vec.fit(docs_seuss)\n",
        "vec.transform(docs_seuss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvqfLNhNb75d"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "The problem with term frequencies (TF) is that common words like \"the\" and \"that\" tend to have high counts and dominate. A better indicator of whether two documents are similar is if they share rare words. For example, the word \"eat\" only appears in two of the Dr. Seuss stories. The presence of that word in two documents is a strong indicator that the documents are similar, so we should give more weight to terms like it.\n",
        "\n",
        "This is the idea behind TF-IDF. We take each term frequency and re-weight it according to how many documents that term appears in, i.e., the **document frequency**. Since we want words that appear in fewer documents to get more weight, we take the **inverse document frequency** (IDF).  We take the logarithm of IDF because the distribution of IDFs is heavily skewed to the right. (Remember the discussion about transforming data from earlier.) When dealing with IDF, the base-10 logarithm ($\\log_{10}$) is typically used. So in the end, the formula for IDF for term $t$ in corpus $D$ is:\n",
        "\n",
        "$$ \\textrm{idf}(t, D) = \\log_{10} \\left(\\frac{\\textrm{\\# of documents in corpus}}{\\textrm{\\# of documents in corpus that contain term } t}\\right) = \\log_{10} \\left(\\frac{|D|}{|d \\in D: t \\in d|}\\right). $$\n",
        "\n",
        "(Sometimes, $1$ will be added to the denominator to prevent division by zero, if there are terms in the vocabulary that do not appear in the corpus.)\n",
        "\n",
        "To calculate **TF-IDF** of term $t$ in document $d$ of corpus $D$, we simply multiply the term frequencies by the inverse document frequencies:\n",
        "\n",
        "$$ \\textrm{tf-idf}(d, t, D) = \\textrm{tf}(d, t) \\cdot \\textrm{idf}(t, D). $$\n",
        "\n",
        "Notice that unlike TF, the TF-IDF representation of a given document depends on the entire corpus of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7TZxq1jcP9A"
      },
      "source": [
        "### Implementation from Scratch\n",
        "\n",
        "Let's first see how to calculate TF-IDF from scratch, using the term-frequency matrix we obtained above. (We will typically use scikit-learn, which we'll see how to do below. We just implement from scratch to make the process a little more concrete.)\n",
        "\n",
        "First we get the document frequencies: how many documents does each word appear in? (Since our corpus has 8 documents, each DF will be between 1 and 8.) Note `(tf > 0)` below creates a data frame of Booleans, with one column for each word, and we can sum each column over all the documents in the corpus to get the DFs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z6-b9Lgdb75e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "i           8\n",
              "am          4\n",
              "sam         1\n",
              "that        8\n",
              "sam-i-am    1\n",
              "           ..\n",
              "grow        1\n",
              "sleep       1\n",
              "zeep.       1\n",
              "gone.       1\n",
              "one.        1\n",
              "Length: 2264, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get document frequencies\n",
        "# (How many documents does each word appear in?)\n",
        "df = (tf > 0).sum(axis=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOOC81BOGen"
      },
      "source": [
        "Now we get the IDFs of each word in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NP10ysjOb75i"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "i           0.000000\n",
              "am          0.693147\n",
              "sam         2.079442\n",
              "that        0.000000\n",
              "sam-i-am    2.079442\n",
              "              ...   \n",
              "grow        2.079442\n",
              "sleep       2.079442\n",
              "zeep.       2.079442\n",
              "gone.       2.079442\n",
              "one.        2.079442\n",
              "Length: 2264, dtype: float64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get IDFs\n",
        "idf = np.log(len(tf) / df)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UStV_TRSPB2H"
      },
      "source": [
        "Finally we multiply the TF and IDF to get the TF-IDF of each word in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H38ZejUGb75m"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>i</th>\n",
              "      <th>am</th>\n",
              "      <th>sam</th>\n",
              "      <th>that</th>\n",
              "      <th>sam-i-am</th>\n",
              "      <th>sam-i-am!</th>\n",
              "      <th>do</th>\n",
              "      <th>not</th>\n",
              "      <th>like</th>\n",
              "      <th>you</th>\n",
              "      <th>...</th>\n",
              "      <th>game?</th>\n",
              "      <th>gack</th>\n",
              "      <th>park</th>\n",
              "      <th>home,</th>\n",
              "      <th>clark.</th>\n",
              "      <th>grow</th>\n",
              "      <th>sleep</th>\n",
              "      <th>zeep.</th>\n",
              "      <th>gone.</th>\n",
              "      <th>one.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>6.238325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.317766</td>\n",
              "      <td>4.158883</td>\n",
              "      <td>4.673599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.875381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.002971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.735908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.934720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.801188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.267063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.468845</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.804159</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>4.158883</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.079442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 2264 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     i        am       sam  that  sam-i-am  sam-i-am!        do  not   \n",
              "0  0.0  2.079442  6.238325   0.0  8.317766   4.158883  4.673599  0.0  \\\n",
              "1  0.0  0.000000  0.000000   0.0  0.000000   0.000000  2.002971  0.0   \n",
              "2  0.0  0.000000  0.000000   0.0  0.000000   0.000000  0.934720  0.0   \n",
              "3  0.0  0.693147  0.000000   0.0  0.000000   0.000000  0.000000  0.0   \n",
              "4  0.0  0.693147  0.000000   0.0  0.000000   0.000000  0.133531  0.0   \n",
              "5  0.0  0.000000  0.000000   0.0  0.000000   0.000000  0.267063  0.0   \n",
              "6  0.0  0.000000  0.000000   0.0  0.000000   0.000000  0.534126  0.0   \n",
              "7  0.0  2.079442  0.000000   0.0  0.000000   0.000000  1.468845  0.0   \n",
              "\n",
              "       like  you  ...     game?      gack      park     home,    clark.   \n",
              "0  5.875381  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000  \\\n",
              "1  1.735908  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2  0.133531  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3  0.801188  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4  0.000000  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "5  0.267063  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "6  0.133531  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7  2.804159  0.0  ...  2.079442  2.079442  2.079442  2.079442  2.079442   \n",
              "\n",
              "       grow     sleep     zeep.     gone.      one.  \n",
              "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "2  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "3  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "4  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "5  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "6  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "7  2.079442  4.158883  2.079442  2.079442  2.079442  \n",
              "\n",
              "[8 rows x 2264 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate TF-IDFs\n",
        "tf_idf = tf * idf\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIhNpIHfb75q"
      },
      "source": [
        "### Implementation using `scikit-learn`\n",
        "\n",
        "We will not generally implement TF-IDF from scratch, like we did above. Instead, we will use Scikit-Learn's `TfidfVectorizer`, which operates similarly to `CountVectorizer`, except that it returns a matrix of the TF-IDF weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Fbu5oi7ib75r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<8x1355 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2345 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vec = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", smooth_idf = False, norm=None)\n",
        "vec.fit(docs_seuss)\n",
        "tf_idf_sparse = vec.transform(docs_seuss)\n",
        "tf_idf_sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AHOFtxPxUy07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>12</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>56</th>\n",
              "      <th>6</th>\n",
              "      <th>98</th>\n",
              "      <th>a</th>\n",
              "      <th>able</th>\n",
              "      <th>about</th>\n",
              "      <th>act</th>\n",
              "      <th>...</th>\n",
              "      <th>yop</th>\n",
              "      <th>yopp</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>yourselves</th>\n",
              "      <th>zans</th>\n",
              "      <th>zeds</th>\n",
              "      <th>zeep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.410011</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.760029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.940007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.470004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.079442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.0</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>1.470004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.238325</td>\n",
              "      <td>47.0</td>\n",
              "      <td>11.931472</td>\n",
              "      <td>10.290025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.386294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.470004</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.400073</td>\n",
              "      <td>6.158883</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.470004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.230033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.238325</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1355 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         12         3         4        56         6        98     a      able   \n",
              "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  59.0  0.000000  \\\n",
              "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  34.0  0.000000   \n",
              "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  25.0  0.000000   \n",
              "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  10.0  0.000000   \n",
              "4  3.079442  0.000000  0.000000  3.079442  3.079442  0.000000  48.0  3.079442   \n",
              "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  34.0  0.000000   \n",
              "6  0.000000  3.079442  3.079442  0.000000  0.000000  3.079442  24.0  0.000000   \n",
              "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  52.0  0.000000   \n",
              "\n",
              "      about       act  ...       yop      yopp   you      young       your   \n",
              "0  0.000000  0.000000  ...  0.000000  0.000000  34.0   0.000000   0.000000  \\\n",
              "1  4.410011  0.000000  ...  0.000000  0.000000  34.0   0.000000  11.760029   \n",
              "2  2.940007  0.000000  ...  0.000000  0.000000   8.0   0.000000   1.470004   \n",
              "3  0.000000  0.000000  ...  0.000000  0.000000   2.0   0.000000   0.000000   \n",
              "4  1.470004  0.000000  ...  0.000000  9.238325  47.0  11.931472  10.290025   \n",
              "5  0.000000  0.000000  ...  0.000000  0.000000   2.0   2.386294   0.000000   \n",
              "6  1.470004  3.079442  ...  0.000000  0.000000  85.0   0.000000  29.400073   \n",
              "7  1.470004  0.000000  ...  3.079442  0.000000  24.0   0.000000  13.230033   \n",
              "\n",
              "   yourself  yourselves      zans      zeds      zeep  \n",
              "0  0.000000    0.000000  0.000000  0.000000  0.000000  \n",
              "1  0.000000    0.000000  0.000000  0.000000  0.000000  \n",
              "2  0.000000    0.000000  0.000000  0.000000  0.000000  \n",
              "3  0.000000    0.000000  0.000000  0.000000  0.000000  \n",
              "4  0.000000    3.079442  0.000000  0.000000  0.000000  \n",
              "5  0.000000    0.000000  0.000000  0.000000  0.000000  \n",
              "6  6.158883    0.000000  0.000000  0.000000  0.000000  \n",
              "7  0.000000    0.000000  9.238325  3.079442  3.079442  \n",
              "\n",
              "[8 rows x 1355 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(\n",
        "    tf_idf_sparse.todense(),\n",
        "    columns=vec.get_feature_names_out()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1ETk1cyRRYW"
      },
      "source": [
        "You might notice that the skikit-learn results do not match what we computed from scratch. The reason is the scikit-learn IDF adds 1 to the definition of IDF we presented above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2kw4sAvRQp-y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>i</th>\n",
              "      <th>am</th>\n",
              "      <th>sam</th>\n",
              "      <th>that</th>\n",
              "      <th>sam-i-am</th>\n",
              "      <th>sam-i-am!</th>\n",
              "      <th>do</th>\n",
              "      <th>not</th>\n",
              "      <th>like</th>\n",
              "      <th>you</th>\n",
              "      <th>...</th>\n",
              "      <th>game?</th>\n",
              "      <th>gack</th>\n",
              "      <th>park</th>\n",
              "      <th>home,</th>\n",
              "      <th>clark.</th>\n",
              "      <th>grow</th>\n",
              "      <th>sleep</th>\n",
              "      <th>zeep.</th>\n",
              "      <th>gone.</th>\n",
              "      <th>one.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71.0</td>\n",
              "      <td>5.079442</td>\n",
              "      <td>9.238325</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.317766</td>\n",
              "      <td>6.158883</td>\n",
              "      <td>39.673599</td>\n",
              "      <td>65.0</td>\n",
              "      <td>49.875381</td>\n",
              "      <td>21.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.002971</td>\n",
              "      <td>37.0</td>\n",
              "      <td>14.735908</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.934720</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.133531</td>\n",
              "      <td>7.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.801188</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18.0</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.133531</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.267063</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.267063</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.534126</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.133531</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>48.0</td>\n",
              "      <td>5.079442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.468845</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.804159</td>\n",
              "      <td>24.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>6.158883</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "      <td>3.079442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 2264 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      i        am       sam  that   sam-i-am  sam-i-am!         do   not   \n",
              "0  71.0  5.079442  9.238325   3.0  12.317766   6.158883  39.673599  65.0  \\\n",
              "1  48.0  0.000000  0.000000  20.0   0.000000   0.000000  17.002971  37.0   \n",
              "2   9.0  0.000000  0.000000   1.0   0.000000   0.000000   7.934720   1.0   \n",
              "3   2.0  1.693147  0.000000   4.0   0.000000   0.000000   0.000000   2.0   \n",
              "4  18.0  1.693147  0.000000  31.0   0.000000   0.000000   1.133531   6.0   \n",
              "5   6.0  0.000000  0.000000  13.0   0.000000   0.000000   2.267063   1.0   \n",
              "6   2.0  0.000000  0.000000  11.0   0.000000   0.000000   4.534126   6.0   \n",
              "7  48.0  5.079442  0.000000   1.0   0.000000   0.000000  12.468845  10.0   \n",
              "\n",
              "        like   you  ...     game?      gack      park     home,    clark.   \n",
              "0  49.875381  21.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000  \\\n",
              "1  14.735908  30.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2   1.133531   7.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3   6.801188   2.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4   0.000000  27.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "5   2.267063   2.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "6   1.133531  43.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7  23.804159  24.0  ...  3.079442  3.079442  3.079442  3.079442  3.079442   \n",
              "\n",
              "       grow     sleep     zeep.     gone.      one.  \n",
              "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "2  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "3  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "4  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "5  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "6  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "7  3.079442  6.158883  3.079442  3.079442  3.079442  \n",
              "\n",
              "[8 rows x 2264 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate TF-IDFs\n",
        "tf * (1 + idf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jdj97RiSRDD"
      },
      "source": [
        "This differnece is a minor techical detail that we won't worry about. (There are still [other ways to define TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)). We'll just use the scikit-learn results. But the following code shows that once we add 1 to our definition of IDF, the \"from scratch\" calculation of TF-IDF matches scikit-learn (because the maximum absolute difference between the two is 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "E4mucMGsQxP9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49.27106466687738"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abs((pd.DataFrame(\n",
        "    tf_idf_sparse.todense(),\n",
        "    columns=vec.get_feature_names_out()\n",
        ") - tf * (1 + idf))).max().max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cycHn7Cjb75v"
      },
      "source": [
        "## Cosine Similarity\n",
        "\n",
        "We now have a representation of each text document as a vector of numbers. Each number can either be a term frequency or a TF-IDF weight. We can visualize each vector as an arrow in a high-dimensional space, where each dimension represents a word. The magnitude of the vector along a dimension represents the \"frequency\" (TF or TF-IDF) of that word in the document. For example, if our vocabulary only contains two words, \"i\" and \"sam\", then the arrows shown below might represent two documents:\n",
        "\n",
        "<img src=\"https://github.com/dlsun/pods/blob/master/10-Textual-Data/vector_space.png?raw=1\" width=\"300\"/>\n",
        "\n",
        "How do we tell if two documents are similar? We need some way to measure the distance between two documents (i.e., two vectors). We could use Euclidean distance, as we have done in the past.\n",
        "\n",
        "<img src=\"https://github.com/dlsun/pods/blob/master/10-Textual-Data/vector_space_euclidean.png?raw=1\" width=\"300\"/>\n",
        "\n",
        "But Euclidean distance does not make sense for TF or TF-IDF vectors. To see why, consider the two documents:\n",
        "\n",
        "1. \"I am Sam.\"\n",
        "2. \"I am Sam. Sam I am.\"\n",
        "\n",
        "The two documents are obviously very similar. But the vector for the second is twice as long as the vector for the first because the second document has twice as many occurrences of each word. This is true whether we use TF or TF-IDF weights. If we calculate the Euclidean distance between these two vectors, then they will seem quite far apart.\n",
        "\n",
        "<img src=\"https://github.com/dlsun/pods/blob/master/10-Textual-Data/vector_space_example.png?raw=1\" width=\"300\"/>\n",
        "\n",
        "With TF and TF-IDF vectors, the distinguishing property is their _direction_. Because the two vectors above point in the same direction, they are similar. We need a distance metric that measures how different their directions are. A natural way to measure the difference between the directions of two vectors is the angle between them.\n",
        "\n",
        "<img src=\"https://github.com/dlsun/pods/blob/master/10-Textual-Data/vector_space_cosine.png?raw=1\" width=\"300\"/>\n",
        "\n",
        "The cosine of the angle between two vectors ${\\bf a}$ and ${\\bf b}$ can be calculated as:\n",
        "\n",
        "$$ \\cos \\theta = \\frac{\\sum a_j b_j}{\\sqrt{\\sum a_j^2} \\sqrt{\\sum b_j^2}}. $$\n",
        "\n",
        "(The numerator is the _dot product_ of vectors ${\\bf a}$ and ${\\bf b}$; the denominator is the product of their lengths.) Although it is possible to work out the angle $\\theta$ from this formula, it is more common to report $\\cos\\theta$ as a measure of similarity between two vectors. This similarity metric is called **cosine similarity**. Notice that when the angle $\\theta$ is close to 0 (i.e., when the two vectors point in nearly the same direction), the value of $\\cos\\theta$ is high (close to 1.0, which is the maximum possible value).\n",
        "\n",
        "The cosine _distance_ is defined as 1 minus the similarity. This makes it so that 0 means that the two vectors point in the same direction:\n",
        "\n",
        "$$ d_{\\cos}({\\bf a}, {\\bf b}) = 1 - \\cos(\\theta({\\bf a}, {\\bf b})) = 1 - \\frac{\\sum a_j b_j}{\\sqrt{\\sum a_j^2} \\sqrt{\\sum b_j^2}}. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQbvOkVcbvK"
      },
      "source": [
        "### Implementation from Scratch\n",
        "\n",
        "Let's calculate the cosine similarity between document 0 (_Green Eggs and Ham_) and document 2 (_Fox in Socks_) using the TF-IDF representation. (Again, we'll typically use scikit-learn, but we'll do it from scratch first to see that scikit-learn matches.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_kagfHiKb75w"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1258410993578232"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the numerator.\n",
        "a = tf_idf_sparse[0, :]\n",
        "b = tf_idf_sparse[2, :]\n",
        "dot = a.multiply(b).sum()\n",
        "\n",
        "# Calculate the terms in the denominator.\n",
        "a_len = np.sqrt(a.multiply(a).sum())\n",
        "b_len = np.sqrt(b.multiply(b).sum())\n",
        "\n",
        "# Cosine similarity is their ratio.\n",
        "dot / (a_len * b_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqj82-h2b750"
      },
      "source": [
        "These two vectors are not very similar, as evidenced by their low cosine similarity (close to 0.0). Let's try to find the most similar documents in the corpus to _Green Eggs and Ham_---in other words, its nearest neighbors. To do this, we will take advantage of _broadcasting_: we will multiply a TF-IDF vector (representing document 0) by the entire TF-IDF matrix and calculate the sum over the columns. This will give us a vector of dot products."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7Nr27ArFb751"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[49399.86992009],\n",
              "        [21095.1096498 ],\n",
              "        [ 5878.95362908],\n",
              "        [ 2528.95862343],\n",
              "        [15276.15082587],\n",
              "        [ 8541.36255536],\n",
              "        [ 8917.18862756],\n",
              "        [14519.02087512]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the numerators.\n",
        "a = tf_idf_sparse[0, :]\n",
        "B = tf_idf_sparse\n",
        "dot = a.multiply(B).sum(axis=1)\n",
        "dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_tuXVdFAb754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "222.26081508014192\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "matrix([[222.26081508],\n",
              "        [239.32261163],\n",
              "        [210.19124777],\n",
              "        [ 77.44263097],\n",
              "        [276.89867775],\n",
              "        [231.2954469 ],\n",
              "        [162.08949899],\n",
              "        [177.22694181]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the denominators.\n",
        "a_len = np.sqrt(a.multiply(a).sum())\n",
        "b_len = np.sqrt(B.multiply(B).sum(axis=1))\n",
        "print(a_len)\n",
        "b_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "m72blwPNb76A"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[1.        ],\n",
              "        [0.39658397],\n",
              "        [0.1258411 ],\n",
              "        [0.14692602],\n",
              "        [0.24821622],\n",
              "        [0.16614879],\n",
              "        [0.24751993],\n",
              "        [0.36859096]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate their ratio to obtain cosine similarities.\n",
        "dot / (a_len * b_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEuizyNvb76E"
      },
      "source": [
        "Now let's put this matrix into a `DataFrame` so that we can easily sort the values in descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1IWk1cYEb76E"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1.000000\n",
              "1    0.396584\n",
              "7    0.368591\n",
              "4    0.248216\n",
              "6    0.247520\n",
              "5    0.166149\n",
              "3    0.146926\n",
              "2    0.125841\n",
              "Name: 0, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cos_similarities = pd.DataFrame(dot / (a_len * b_len))[0]\n",
        "most_similar = cos_similarities.sort_values(ascending=False)\n",
        "most_similar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELG94ygFb76H"
      },
      "source": [
        "Of course, the most similar document in the corpus to _Green Eggs and Ham_ (with a perfect cosine similarity of 1.0) is itself. But the next most similar text is _The Cat in the Hat_ (the document with index 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBVAM4hmb76I"
      },
      "source": [
        "### Implementation using scikit-learn\n",
        "\n",
        "It is also possible to calculate cosine similarities/distances in `scikit-learn` using the same API that we used to calculate Euclidean (and Manhattan) distances earier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0ZoMACMMb76J"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.39658397, 0.1258411 , 0.14692602, 0.24821622,\n",
              "        0.16614879, 0.24751993, 0.36859096],\n",
              "       [0.39658397, 1.        , 0.17904195, 0.31095348, 0.55961395,\n",
              "        0.49882428, 0.41849834, 0.62425905],\n",
              "       [0.1258411 , 0.17904195, 1.        , 0.08946843, 0.18424177,\n",
              "        0.1293746 , 0.15848004, 0.19644695],\n",
              "       [0.14692602, 0.31095348, 0.08946843, 1.        , 0.23619993,\n",
              "        0.20138896, 0.14432695, 0.34237812],\n",
              "       [0.24821622, 0.55961395, 0.18424177, 0.23619993, 1.        ,\n",
              "        0.54243474, 0.45903587, 0.48027592],\n",
              "       [0.16614879, 0.49882428, 0.1293746 , 0.20138896, 0.54243474,\n",
              "        1.        , 0.29141396, 0.37161018],\n",
              "       [0.24751993, 0.41849834, 0.15848004, 0.14432695, 0.45903587,\n",
              "        0.29141396, 1.        , 0.39016939],\n",
              "       [0.36859096, 0.62425905, 0.19644695, 0.34237812, 0.48027592,\n",
              "        0.37161018, 0.39016939, 1.        ]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
        "\n",
        "cosine_similarity(tf_idf_sparse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTWQae5xb76M"
      },
      "source": [
        "The $(i, j)$th entry of this matrix represents the cosine similarity between the $i$th and $j$th documents. So the first row of this matrix contains the similarities between _Green Eggs and Ham_ and the other documents in the corpus. Check that these numbers match the ones we obtained manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vm7f6Jncb76N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 0.39658397, 0.1258411 , 0.14692602, 0.24821622,\n",
              "       0.16614879, 0.24751993, 0.36859096])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity(tf_idf_sparse)[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
